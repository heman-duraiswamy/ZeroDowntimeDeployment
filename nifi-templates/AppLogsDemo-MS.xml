<?xml version="1.0" encoding="UTF-8" standalone="yes"?><template><description></description><name>AppLogsDemo-MS</name><snippet><connections><id>35147b44-9598-4b55-baca-d6d33c310024</id><parentGroupId>754b7b45-9a4c-4a08-bc09-6d7c28965055</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>754b7b45-9a4c-4a08-bc09-6d7c28965055</groupId><id>c8c69096-d30a-409d-a9f8-d21ff6c0bb02</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>cb5b83d9-1b34-4057-a2ac-2f7236ee2032</groupId><id>4d1e14ee-ae64-4722-aab8-4ec72d4327f5</id><type>OUTPUT_PORT</type></source><zIndex>0</zIndex></connections><connections><id>2075043e-e7c5-4476-a029-648819c296e3</id><parentGroupId>754b7b45-9a4c-4a08-bc09-6d7c28965055</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>754b7b45-9a4c-4a08-bc09-6d7c28965055</groupId><id>1f0d4382-c709-4a00-93ea-dbab7e9a561e</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>CRIT</selectedRelationships><selectedRelationships>ERROR</selectedRelationships><source><groupId>754b7b45-9a4c-4a08-bc09-6d7c28965055</groupId><id>c8c69096-d30a-409d-a9f8-d21ff6c0bb02</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>682aeeb3-6a5e-4670-a9eb-672c1cf04161</id><parentGroupId>754b7b45-9a4c-4a08-bc09-6d7c28965055</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>754b7b45-9a4c-4a08-bc09-6d7c28965055</groupId><id>c8c69096-d30a-409d-a9f8-d21ff6c0bb02</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>754b7b45-9a4c-4a08-bc09-6d7c28965055</groupId><id>58bf76f0-bb42-4cdc-9b0c-c003e9d23a8e</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>a0154395-2ae1-41ed-9e86-82bc30a678dc</id><parentGroupId>754b7b45-9a4c-4a08-bc09-6d7c28965055</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>46834fff-9e60-4ae0-b810-b8cb9a721dad</groupId><id>36ac399d-7c03-4f29-af87-407b3a1db806</id><type>INPUT_PORT</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>ALL</selectedRelationships><selectedRelationships>unmatched</selectedRelationships><source><groupId>754b7b45-9a4c-4a08-bc09-6d7c28965055</groupId><id>c8c69096-d30a-409d-a9f8-d21ff6c0bb02</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><processGroups><id>cb5b83d9-1b34-4057-a2ac-2f7236ee2032</id><parentGroupId>754b7b45-9a4c-4a08-bc09-6d7c28965055</parentGroupId><position><x>-833.3803124539473</x><y>275.8682081082202</y></position><activeRemotePortCount>0</activeRemotePortCount><comments></comments><contents><connections><id>b7abd8e0-761b-487b-a01c-0f6982b78fc4</id><parentGroupId>cb5b83d9-1b34-4057-a2ac-2f7236ee2032</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>cb5b83d9-1b34-4057-a2ac-2f7236ee2032</groupId><id>89296cef-1d5f-4391-a14e-116802e94164</id><type>FUNNEL</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>cb5b83d9-1b34-4057-a2ac-2f7236ee2032</groupId><id>8a9c7094-a3e2-4743-982b-e6d6af3ec092</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>d820e965-9c33-490a-85a3-cd49ce13d078</id><parentGroupId>cb5b83d9-1b34-4057-a2ac-2f7236ee2032</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>cb5b83d9-1b34-4057-a2ac-2f7236ee2032</groupId><id>89296cef-1d5f-4391-a14e-116802e94164</id><type>FUNNEL</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>cb5b83d9-1b34-4057-a2ac-2f7236ee2032</groupId><id>e6cac10b-e78c-461d-ac18-bb18043e6d51</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>8953dca5-63ba-4462-8a96-02f878798138</id><parentGroupId>cb5b83d9-1b34-4057-a2ac-2f7236ee2032</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>cb5b83d9-1b34-4057-a2ac-2f7236ee2032</groupId><id>4d1e14ee-ae64-4722-aab8-4ec72d4327f5</id><type>OUTPUT_PORT</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>cb5b83d9-1b34-4057-a2ac-2f7236ee2032</groupId><id>89296cef-1d5f-4391-a14e-116802e94164</id><type>FUNNEL</type></source><zIndex>0</zIndex></connections><connections><id>5cbd8d28-f602-49ad-9081-695e1fce5e5c</id><parentGroupId>cb5b83d9-1b34-4057-a2ac-2f7236ee2032</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>cb5b83d9-1b34-4057-a2ac-2f7236ee2032</groupId><id>89296cef-1d5f-4391-a14e-116802e94164</id><type>FUNNEL</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>cb5b83d9-1b34-4057-a2ac-2f7236ee2032</groupId><id>adad0c30-6665-4449-a282-d5ca1c3ae25c</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><funnels><id>89296cef-1d5f-4391-a14e-116802e94164</id><parentGroupId>cb5b83d9-1b34-4057-a2ac-2f7236ee2032</parentGroupId><position><x>710.8399911514397</x><y>142.39227614842477</y></position></funnels><outputPorts><id>4d1e14ee-ae64-4722-aab8-4ec72d4327f5</id><parentGroupId>cb5b83d9-1b34-4057-a2ac-2f7236ee2032</parentGroupId><position><x>995.9600131240958</x><y>165.43229079686225</y></position><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><name>TailedAppLogs</name><state>STOPPED</state><type>OUTPUT_PORT</type></outputPorts><processors><id>adad0c30-6665-4449-a282-d5ca1c3ae25c</id><parentGroupId>cb5b83d9-1b34-4057-a2ac-2f7236ee2032</parentGroupId><position><x>57.68010772858804</x><y>107.52852126561226</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>File to Tail</key><value><description>Fully-qualified filename of the file that should be tailed</description><displayName>File to Tail</displayName><dynamic>false</dynamic><name>File to Tail</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Rolling Filename Pattern</key><value><description>If the file to tail &quot;rolls over&quot; as would be the case with log files, this filename pattern will be used to identify files that have rolled over so that if NiFi is restarted, and the file has rolled over, it will be able to pick up where it left off. This pattern supports wildcard characters * and ? and will assume that the files that have rolled over live in the same directory as the file being tailed.</description><displayName>Rolling Filename Pattern</displayName><dynamic>false</dynamic><name>Rolling Filename Pattern</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>State File</key><value><description>Specifies the file that should be used for storing state about what data has been ingested so that upon restart NiFi can resume from where it left off</description><displayName>State File</displayName><dynamic>false</dynamic><name>State File</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Initial Start Position</key><value><allowableValues><description>Start with the oldest data that matches the Rolling Filename Pattern and then begin reading from the File to Tail</description><displayName>Beginning of Time</displayName><value>Beginning of Time</value></allowableValues><allowableValues><description>Start with the beginning of the File to Tail. Do not ingest any data that has already been rolled over</description><displayName>Beginning of File</displayName><value>Beginning of File</value></allowableValues><allowableValues><description>Start with the data at the end of the File to Tail. Do not ingest any data thas has already been rolled over or any data in the File to Tail that has already been written.</description><displayName>Current Time</displayName><value>Current Time</value></allowableValues><defaultValue>Beginning of File</defaultValue><description>When the Processor first begins to tail data, this property specifies where the Processor should begin reading data. Once data has been ingested from the file, the Processor will continue from the last point from which it has received data.</description><displayName>Initial Start Position</displayName><dynamic>false</dynamic><name>Initial Start Position</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>File Location</key><value><allowableValues><description>File is located on a local disk drive. Each node in a cluster will tail a different file.</description><displayName>Local</displayName><value>Local</value></allowableValues><allowableValues><description>File is located on a remote resource. This Processor will store state across the cluster so that it can be run on Primary Node Only and a new Primary Node can pick up where the last one left off.</description><displayName>Remote</displayName><value>Remote</value></allowableValues><defaultValue>Local</defaultValue><description>Specifies where the file is located, so that state can be stored appropriately in order to ensure that all data is consumed without duplicating data upon restart of NiFi</description><displayName>File Location</displayName><dynamic>false</dynamic><name>File Location</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>10 sec</penaltyDuration><properties><entry><key>File to Tail</key><value>/root/demo/ms/generated_logs/applog-server002.log</value></entry><entry><key>Rolling Filename Pattern</key></entry><entry><key>State File</key></entry><entry><key>Initial Start Position</key></entry><entry><key>File Location</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Applog-server002</name><relationships><autoTerminate>false</autoTerminate><description>All FlowFiles are routed to this Relationship.</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>false</supportsParallelProcessing><type>org.apache.nifi.processors.standard.TailFile</type></processors><processors><id>8a9c7094-a3e2-4743-982b-e6d6af3ec092</id><parentGroupId>cb5b83d9-1b34-4057-a2ac-2f7236ee2032</parentGroupId><position><x>56.4400106826896</x><y>-57.15145138300835</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>File to Tail</key><value><description>Fully-qualified filename of the file that should be tailed</description><displayName>File to Tail</displayName><dynamic>false</dynamic><name>File to Tail</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Rolling Filename Pattern</key><value><description>If the file to tail &quot;rolls over&quot; as would be the case with log files, this filename pattern will be used to identify files that have rolled over so that if NiFi is restarted, and the file has rolled over, it will be able to pick up where it left off. This pattern supports wildcard characters * and ? and will assume that the files that have rolled over live in the same directory as the file being tailed.</description><displayName>Rolling Filename Pattern</displayName><dynamic>false</dynamic><name>Rolling Filename Pattern</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>State File</key><value><description>Specifies the file that should be used for storing state about what data has been ingested so that upon restart NiFi can resume from where it left off</description><displayName>State File</displayName><dynamic>false</dynamic><name>State File</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Initial Start Position</key><value><allowableValues><description>Start with the oldest data that matches the Rolling Filename Pattern and then begin reading from the File to Tail</description><displayName>Beginning of Time</displayName><value>Beginning of Time</value></allowableValues><allowableValues><description>Start with the beginning of the File to Tail. Do not ingest any data that has already been rolled over</description><displayName>Beginning of File</displayName><value>Beginning of File</value></allowableValues><allowableValues><description>Start with the data at the end of the File to Tail. Do not ingest any data thas has already been rolled over or any data in the File to Tail that has already been written.</description><displayName>Current Time</displayName><value>Current Time</value></allowableValues><defaultValue>Beginning of File</defaultValue><description>When the Processor first begins to tail data, this property specifies where the Processor should begin reading data. Once data has been ingested from the file, the Processor will continue from the last point from which it has received data.</description><displayName>Initial Start Position</displayName><dynamic>false</dynamic><name>Initial Start Position</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>File Location</key><value><allowableValues><description>File is located on a local disk drive. Each node in a cluster will tail a different file.</description><displayName>Local</displayName><value>Local</value></allowableValues><allowableValues><description>File is located on a remote resource. This Processor will store state across the cluster so that it can be run on Primary Node Only and a new Primary Node can pick up where the last one left off.</description><displayName>Remote</displayName><value>Remote</value></allowableValues><defaultValue>Local</defaultValue><description>Specifies where the file is located, so that state can be stored appropriately in order to ensure that all data is consumed without duplicating data upon restart of NiFi</description><displayName>File Location</displayName><dynamic>false</dynamic><name>File Location</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>10 sec</penaltyDuration><properties><entry><key>File to Tail</key><value>/root/demo/ms/generated_logs/applog-server001.log</value></entry><entry><key>Rolling Filename Pattern</key></entry><entry><key>State File</key></entry><entry><key>Initial Start Position</key></entry><entry><key>File Location</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Applog-server001</name><relationships><autoTerminate>false</autoTerminate><description>All FlowFiles are routed to this Relationship.</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>false</supportsParallelProcessing><type>org.apache.nifi.processors.standard.TailFile</type></processors><processors><id>e6cac10b-e78c-461d-ac18-bb18043e6d51</id><parentGroupId>cb5b83d9-1b34-4057-a2ac-2f7236ee2032</parentGroupId><position><x>59.84001983796304</x><y>276.00851985417427</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>File to Tail</key><value><description>Fully-qualified filename of the file that should be tailed</description><displayName>File to Tail</displayName><dynamic>false</dynamic><name>File to Tail</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Rolling Filename Pattern</key><value><description>If the file to tail &quot;rolls over&quot; as would be the case with log files, this filename pattern will be used to identify files that have rolled over so that if NiFi is restarted, and the file has rolled over, it will be able to pick up where it left off. This pattern supports wildcard characters * and ? and will assume that the files that have rolled over live in the same directory as the file being tailed.</description><displayName>Rolling Filename Pattern</displayName><dynamic>false</dynamic><name>Rolling Filename Pattern</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>State File</key><value><description>Specifies the file that should be used for storing state about what data has been ingested so that upon restart NiFi can resume from where it left off</description><displayName>State File</displayName><dynamic>false</dynamic><name>State File</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Initial Start Position</key><value><allowableValues><description>Start with the oldest data that matches the Rolling Filename Pattern and then begin reading from the File to Tail</description><displayName>Beginning of Time</displayName><value>Beginning of Time</value></allowableValues><allowableValues><description>Start with the beginning of the File to Tail. Do not ingest any data that has already been rolled over</description><displayName>Beginning of File</displayName><value>Beginning of File</value></allowableValues><allowableValues><description>Start with the data at the end of the File to Tail. Do not ingest any data thas has already been rolled over or any data in the File to Tail that has already been written.</description><displayName>Current Time</displayName><value>Current Time</value></allowableValues><defaultValue>Beginning of File</defaultValue><description>When the Processor first begins to tail data, this property specifies where the Processor should begin reading data. Once data has been ingested from the file, the Processor will continue from the last point from which it has received data.</description><displayName>Initial Start Position</displayName><dynamic>false</dynamic><name>Initial Start Position</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>File Location</key><value><allowableValues><description>File is located on a local disk drive. Each node in a cluster will tail a different file.</description><displayName>Local</displayName><value>Local</value></allowableValues><allowableValues><description>File is located on a remote resource. This Processor will store state across the cluster so that it can be run on Primary Node Only and a new Primary Node can pick up where the last one left off.</description><displayName>Remote</displayName><value>Remote</value></allowableValues><defaultValue>Local</defaultValue><description>Specifies where the file is located, so that state can be stored appropriately in order to ensure that all data is consumed without duplicating data upon restart of NiFi</description><displayName>File Location</displayName><dynamic>false</dynamic><name>File Location</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>10 sec</penaltyDuration><properties><entry><key>File to Tail</key><value>/root/demo/ms/generated_logs/applog-server003.log</value></entry><entry><key>Rolling Filename Pattern</key></entry><entry><key>State File</key></entry><entry><key>Initial Start Position</key></entry><entry><key>File Location</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Applog-server003</name><relationships><autoTerminate>false</autoTerminate><description>All FlowFiles are routed to this Relationship.</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>false</supportsParallelProcessing><type>org.apache.nifi.processors.standard.TailFile</type></processors></contents><disabledCount>0</disabledCount><inactiveRemotePortCount>0</inactiveRemotePortCount><inputPortCount>0</inputPortCount><invalidCount>0</invalidCount><name>TailLogFiles</name><outputPortCount>1</outputPortCount><parent><id>754b7b45-9a4c-4a08-bc09-6d7c28965055</id><name>NiFi Flow</name></parent><runningCount>0</runningCount><stoppedCount>4</stoppedCount></processGroups><processGroups><id>46834fff-9e60-4ae0-b810-b8cb9a721dad</id><parentGroupId>754b7b45-9a4c-4a08-bc09-6d7c28965055</parentGroupId><position><x>-926.6722773363317</x><y>738.5169212840078</y></position><activeRemotePortCount>0</activeRemotePortCount><comments></comments><contents><connections><id>f17e4755-22e1-4af0-ab96-3f38d2fde2c6</id><parentGroupId>46834fff-9e60-4ae0-b810-b8cb9a721dad</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>46834fff-9e60-4ae0-b810-b8cb9a721dad</groupId><id>6c4fb7a1-e3a3-49a1-a603-47a2c954207b</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>merged</selectedRelationships><source><groupId>46834fff-9e60-4ae0-b810-b8cb9a721dad</groupId><id>0f15e7bb-6960-4976-8f2c-2965ecca604e</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>873c2029-2f07-4342-a66e-edb98726754a</id><parentGroupId>46834fff-9e60-4ae0-b810-b8cb9a721dad</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><bends><x>-774.7459370289534</x><y>923.2555678005479</y></bends><bends><x>-774.7459370289534</x><y>973.2555678005479</y></bends><destination><groupId>46834fff-9e60-4ae0-b810-b8cb9a721dad</groupId><id>6e7cc849-8765-4910-b418-89bf246443f7</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>46834fff-9e60-4ae0-b810-b8cb9a721dad</groupId><id>6e7cc849-8765-4910-b418-89bf246443f7</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>d4093f48-8c5e-4574-9c35-baaa7f6cb78c</id><parentGroupId>46834fff-9e60-4ae0-b810-b8cb9a721dad</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>46834fff-9e60-4ae0-b810-b8cb9a721dad</groupId><id>0f15e7bb-6960-4976-8f2c-2965ecca604e</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>46834fff-9e60-4ae0-b810-b8cb9a721dad</groupId><id>36ac399d-7c03-4f29-af87-407b3a1db806</id><type>INPUT_PORT</type></source><zIndex>0</zIndex></connections><connections><id>033a8f72-36b3-4d59-b62e-3e8b922063ee</id><parentGroupId>46834fff-9e60-4ae0-b810-b8cb9a721dad</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>46834fff-9e60-4ae0-b810-b8cb9a721dad</groupId><id>6e7cc849-8765-4910-b418-89bf246443f7</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>46834fff-9e60-4ae0-b810-b8cb9a721dad</groupId><id>6c4fb7a1-e3a3-49a1-a603-47a2c954207b</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><inputPorts><id>36ac399d-7c03-4f29-af87-407b3a1db806</id><parentGroupId>46834fff-9e60-4ae0-b810-b8cb9a721dad</parentGroupId><position><x>-1660.3000534555456</x><y>550.2102697675211</y></position><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><name>WriteToHDFS</name><state>STOPPED</state><type>INPUT_PORT</type></inputPorts><processors><id>0f15e7bb-6960-4976-8f2c-2965ecca604e</id><parentGroupId>46834fff-9e60-4ae0-b810-b8cb9a721dad</parentGroupId><position><x>-1186.024327783178</x><y>520.2245686413564</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Merge Strategy</key><value><allowableValues><description>Generates 'bins' of FlowFiles and fills each bin as full as possible. FlowFiles are placed into a bin based on their size and optionally their attributes (if the &lt;Correlation Attribute&gt; property is set)</description><displayName>Bin-Packing Algorithm</displayName><value>Bin-Packing Algorithm</value></allowableValues><allowableValues><description>Combines fragments that are associated by attributes back into a single cohesive FlowFile. If using this strategy, all FlowFiles must have the attributes &lt;fragment.identifier&gt;, &lt;fragment.count&gt;, and &lt;fragment.index&gt; or alternatively (for backward compatibility purposes) &lt;segment.identifier&gt;, &lt;segment.count&gt;, and &lt;segment.index&gt;. All FlowFiles with the same value for &quot;fragment.identifier&quot; will be grouped together. All FlowFiles in this group must have the same value for the &quot;fragment.count&quot; attribute. All FlowFiles in this group must have a unique value for the &quot;fragment.index&quot; attribute between 0 and the value of the &quot;fragment.count&quot; attribute.</description><displayName>Defragment</displayName><value>Defragment</value></allowableValues><defaultValue>Bin-Packing Algorithm</defaultValue><description>Specifies the algorithm used to merge content. The 'Defragment' algorithm combines fragments that are associated by attributes back into a single cohesive FlowFile. The 'Bin-Packing Algorithm' generates a FlowFile populated by arbitrarily chosen FlowFiles</description><displayName>Merge Strategy</displayName><dynamic>false</dynamic><name>Merge Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Merge Format</key><value><allowableValues><description>A bin of FlowFiles will be combined into a single TAR file. The FlowFiles' &lt;path&gt; attribute will be used to create a directory in the TAR file if the &lt;Keep Paths&gt; property is set to true; otherwise, all FlowFiles will be added at the root of the TAR file. If a FlowFile has an attribute named &lt;tar.permissions&gt; that is 3 characters, each between 0-7, that attribute will be used as the TAR entry's 'mode'.</description><displayName>TAR</displayName><value>TAR</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single ZIP file. The FlowFiles' &lt;path&gt; attribute will be used to create a directory in the ZIP file if the &lt;Keep Paths&gt; property is set to true; otherwise, all FlowFiles will be added at the root of the ZIP file. The &lt;Compression Level&gt; property indicates the ZIP compression to use.</description><displayName>ZIP</displayName><value>ZIP</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 3 FlowFile Stream</description><displayName>FlowFile Stream, v3</displayName><value>FlowFile Stream, v3</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 2 FlowFile Stream</description><displayName>FlowFile Stream, v2</displayName><value>FlowFile Stream, v2</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 1 FlowFile Package</description><displayName>FlowFile Tar, v1</displayName><value>FlowFile Tar, v1</value></allowableValues><allowableValues><description>The contents of all FlowFiles will be concatenated together into a single FlowFile</description><displayName>Binary Concatenation</displayName><value>Binary Concatenation</value></allowableValues><allowableValues><description>The Avro contents of all FlowFiles will be concatenated together into a single FlowFile</description><displayName>Avro</displayName><value>Avro</value></allowableValues><defaultValue>Binary Concatenation</defaultValue><description>Determines the format that will be used to merge the content.</description><displayName>Merge Format</displayName><dynamic>false</dynamic><name>Merge Format</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Attribute Strategy</key><value><allowableValues><displayName>Keep Only Common Attributes</displayName><value>Keep Only Common Attributes</value></allowableValues><allowableValues><displayName>Keep All Unique Attributes</displayName><value>Keep All Unique Attributes</value></allowableValues><defaultValue>Keep Only Common Attributes</defaultValue><description>Determines which FlowFile attributes should be added to the bundle. If 'Keep All Unique Attributes' is selected, any attribute on any FlowFile that gets bundled will be kept unless its value conflicts with the value from another FlowFile. If 'Keep Only Common Attributes' is selected, only the attributes that exist on all FlowFiles in the bundle, with the same value, will be preserved.</description><displayName>Attribute Strategy</displayName><dynamic>false</dynamic><name>Attribute Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Correlation Attribute Name</key><value><description>If specified, like FlowFiles will be binned together, where 'like FlowFiles' means FlowFiles that have the same value for this Attribute. If not specified, FlowFiles are bundled by the order in which they are pulled from the queue.</description><displayName>Correlation Attribute Name</displayName><dynamic>false</dynamic><name>Correlation Attribute Name</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Minimum Number of Entries</key><value><defaultValue>1</defaultValue><description>The minimum number of files to include in a bundle</description><displayName>Minimum Number of Entries</displayName><dynamic>false</dynamic><name>Minimum Number of Entries</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum Number of Entries</key><value><description>The maximum number of files to include in a bundle. If not specified, there is no maximum.</description><displayName>Maximum Number of Entries</displayName><dynamic>false</dynamic><name>Maximum Number of Entries</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Minimum Group Size</key><value><defaultValue>0 B</defaultValue><description>The minimum size of for the bundle</description><displayName>Minimum Group Size</displayName><dynamic>false</dynamic><name>Minimum Group Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum Group Size</key><value><description>The maximum size for the bundle. If not specified, there is no maximum.</description><displayName>Maximum Group Size</displayName><dynamic>false</dynamic><name>Maximum Group Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Max Bin Age</key><value><description>The maximum age of a Bin that will trigger a Bin to be complete. Expected format is &lt;duration&gt; &lt;time unit&gt; where &lt;duration&gt; is a positive integer and time unit is one of seconds, minutes, hours</description><displayName>Max Bin Age</displayName><dynamic>false</dynamic><name>Max Bin Age</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum number of Bins</key><value><defaultValue>100</defaultValue><description>Specifies the maximum number of bins that can be held in memory at any one time</description><displayName>Maximum number of Bins</displayName><dynamic>false</dynamic><name>Maximum number of Bins</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Delimiter Strategy</key><value><allowableValues><description>The values of Header, Footer, and Demarcator will be retrieved from the contents of a file</description><displayName>Filename</displayName><value>Filename</value></allowableValues><allowableValues><description>The values of Header, Footer, and Demarcator will be specified as property values</description><displayName>Text</displayName><value>Text</value></allowableValues><defaultValue>Filename</defaultValue><description>Determines if Header, Footer, and Demarcator should point to files containing the respective content, or if the values of the properties should be used as the content.</description><displayName>Delimiter Strategy</displayName><dynamic>false</dynamic><name>Delimiter Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Header File</key><value><description>Filename specifying the header to use. If not specified, no header is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Header</displayName><dynamic>false</dynamic><name>Header File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Footer File</key><value><description>Filename specifying the footer to use. If not specified, no footer is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Footer</displayName><dynamic>false</dynamic><name>Footer File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Demarcator File</key><value><description>Filename specifying the demarcator to use. If not specified, no demarcator is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Demarcator</displayName><dynamic>false</dynamic><name>Demarcator File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Compression Level</key><value><allowableValues><displayName>0</displayName><value>0</value></allowableValues><allowableValues><displayName>1</displayName><value>1</value></allowableValues><allowableValues><displayName>2</displayName><value>2</value></allowableValues><allowableValues><displayName>3</displayName><value>3</value></allowableValues><allowableValues><displayName>4</displayName><value>4</value></allowableValues><allowableValues><displayName>5</displayName><value>5</value></allowableValues><allowableValues><displayName>6</displayName><value>6</value></allowableValues><allowableValues><displayName>7</displayName><value>7</value></allowableValues><allowableValues><displayName>8</displayName><value>8</value></allowableValues><allowableValues><displayName>9</displayName><value>9</value></allowableValues><defaultValue>1</defaultValue><description>Specifies the compression level to use when using the Zip Merge Format; if not using the Zip Merge Format, this value is ignored</description><displayName>Compression Level</displayName><dynamic>false</dynamic><name>Compression Level</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Keep Path</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>If using the Zip or Tar Merge Format, specifies whether or not the FlowFiles' paths should be included in their entry names; if using other merge strategy, this value is ignored</description><displayName>Keep Path</displayName><dynamic>false</dynamic><name>Keep Path</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>10 sec</penaltyDuration><properties><entry><key>Merge Strategy</key></entry><entry><key>Merge Format</key></entry><entry><key>Attribute Strategy</key></entry><entry><key>Correlation Attribute Name</key></entry><entry><key>Minimum Number of Entries</key><value>25</value></entry><entry><key>Maximum Number of Entries</key></entry><entry><key>Minimum Group Size</key><value>5 kb</value></entry><entry><key>Maximum Group Size</key></entry><entry><key>Max Bin Age</key></entry><entry><key>Maximum number of Bins</key></entry><entry><key>Delimiter Strategy</key></entry><entry><key>Header File</key></entry><entry><key>Footer File</key></entry><entry><key>Demarcator File</key></entry><entry><key>Compression Level</key></entry><entry><key>Keep Path</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>MergeContent</name><relationships><autoTerminate>true</autoTerminate><description>If the bundle cannot be created, all FlowFiles that would have been used to created the bundle will be transferred to failure</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>The FlowFile containing the merged content</description><name>merged</name></relationships><relationships><autoTerminate>true</autoTerminate><description>The FlowFiles that were used to create the bundle</description><name>original</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.MergeContent</type></processors><processors><id>6c4fb7a1-e3a3-49a1-a603-47a2c954207b</id><parentGroupId>46834fff-9e60-4ae0-b810-b8cb9a721dad</parentGroupId><position><x>-1184.4855074909697</x><y>706.0938916429989</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Delete Attributes Expression</key><value><description>Regular expression for attributes to be deleted from flowfiles.</description><displayName>Delete Attributes Expression</displayName><dynamic>false</dynamic><name>Delete Attributes Expression</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>filename</key><value><description></description><displayName>filename</displayName><dynamic>true</dynamic><name>filename</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>log.type</key><value><description></description><displayName>log.type</displayName><dynamic>true</dynamic><name>log.type</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>10 sec</penaltyDuration><properties><entry><key>Delete Attributes Expression</key></entry><entry><key>filename</key><value>applogs-${uuid}</value></entry><entry><key>log.type</key><value>applogs</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>UpdateAttribute</name><relationships><autoTerminate>false</autoTerminate><description>All FlowFiles are routed to this relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.attributes.UpdateAttribute</type></processors><processors><id>6e7cc849-8765-4910-b418-89bf246443f7</id><parentGroupId>46834fff-9e60-4ae0-b810-b8cb9a721dad</parentGroupId><position><x>-1183.7459370289534</x><y>898.2555678005479</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>2</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Relogin Period</key><value><defaultValue>4 hours</defaultValue><description>Period of time which should pass before attempting a kerberos relogin</description><displayName>Kerberos Relogin Period</displayName><dynamic>false</dynamic><name>Kerberos Relogin Period</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Directory</key><value><description>The parent HDFS directory to which files should be written</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Conflict Resolution Strategy</key><value><allowableValues><displayName>replace</displayName><value>replace</value></allowableValues><allowableValues><displayName>ignore</displayName><value>ignore</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>fail</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Conflict Resolution Strategy</displayName><dynamic>false</dynamic><name>Conflict Resolution Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Block Size</key><value><description>Size of each block as written to HDFS. This overrides the Hadoop Configuration</description><displayName>Block Size</displayName><dynamic>false</dynamic><name>Block Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>IO Buffer Size</key><value><description>Amount of memory to use to buffer file contents during IO. This overrides the Hadoop Configuration</description><displayName>IO Buffer Size</displayName><dynamic>false</dynamic><name>IO Buffer Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Replication</key><value><description>Number of times that HDFS will replicate each file. This overrides the Hadoop Configuration</description><displayName>Replication</displayName><dynamic>false</dynamic><name>Replication</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Permissions umask</key><value><description>A umask represented as an octal number which determines the permissions of files written to HDFS. This overrides the Hadoop Configuration dfs.umaskmode</description><displayName>Permissions umask</displayName><dynamic>false</dynamic><name>Permissions umask</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Owner</key><value><description>Changes the owner of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change owner</description><displayName>Remote Owner</displayName><dynamic>false</dynamic><name>Remote Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Group</key><value><description>Changes the group of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change group</description><displayName>Remote Group</displayName><dynamic>false</dynamic><name>Remote Group</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Compression codec</key><value><allowableValues><displayName>NONE</displayName><value>NONE</value></allowableValues><allowableValues><displayName>DEFAULT</displayName><value>DEFAULT</value></allowableValues><allowableValues><displayName>BZIP</displayName><value>BZIP</value></allowableValues><allowableValues><displayName>GZIP</displayName><value>GZIP</value></allowableValues><allowableValues><displayName>LZ4</displayName><value>LZ4</value></allowableValues><allowableValues><displayName>SNAPPY</displayName><value>SNAPPY</value></allowableValues><allowableValues><displayName>AUTOMATIC</displayName><value>AUTOMATIC</value></allowableValues><defaultValue>NONE</defaultValue><description></description><displayName>Compression codec</displayName><dynamic>false</dynamic><name>Compression codec</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Hadoop Configuration Resources</key><value>/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml</value></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry><entry><key>Kerberos Relogin Period</key></entry><entry><key>Directory</key><value>/etc/logs/${log.type}/${now():format('yyyy/MM/dd/HH')}</value></entry><entry><key>Conflict Resolution Strategy</key></entry><entry><key>Block Size</key></entry><entry><key>IO Buffer Size</key></entry><entry><key>Replication</key></entry><entry><key>Permissions umask</key></entry><entry><key>Remote Owner</key></entry><entry><key>Remote Group</key></entry><entry><key>Compression codec</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>PutLogsToHDFS</name><relationships><autoTerminate>false</autoTerminate><description>Files that could not be written to HDFS for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Files that have been successfully written to HDFS are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.hadoop.PutHDFS</type></processors></contents><disabledCount>0</disabledCount><inactiveRemotePortCount>0</inactiveRemotePortCount><inputPortCount>1</inputPortCount><invalidCount>0</invalidCount><name>PutToHDFS</name><outputPortCount>0</outputPortCount><parent><id>754b7b45-9a4c-4a08-bc09-6d7c28965055</id><name>NiFi Flow</name></parent><runningCount>0</runningCount><stoppedCount>4</stoppedCount></processGroups><processors><id>1f0d4382-c709-4a00-93ea-dbab7e9a561e</id><parentGroupId>754b7b45-9a4c-4a08-bc09-6d7c28965055</parentGroupId><position><x>-109.37155686562642</x><y>761.2014153003693</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>5</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Known Brokers</key><value><description>A comma-separated list of known Kafka Brokers in the format &lt;host&gt;:&lt;port&gt;</description><displayName>Known Brokers</displayName><dynamic>false</dynamic><name>Known Brokers</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Topic Name</key><value><description>The Kafka Topic of interest</description><displayName>Topic Name</displayName><dynamic>false</dynamic><name>Topic Name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Partition Strategy</key><value><allowableValues><description>Messages will be assigned partitions in a round-robin fashion, sending the first message to Partition 1, the next Partition to Partition 2, and so on, wrapping as necessary.</description><displayName>Round Robin</displayName><value>Round Robin</value></allowableValues><allowableValues><description>Messages will be assigned to random partitions.</description><displayName>Random</displayName><value>Random Robin</value></allowableValues><allowableValues><description>The &lt;Partition&gt; property will be used to determine the partition. All messages within the same FlowFile will be assigned to the same partition.</description><displayName>User-Defined</displayName><value>User-Defined</value></allowableValues><defaultValue>Round Robin</defaultValue><description>Specifies how messages should be partitioned when sent to Kafka</description><displayName>Partition Strategy</displayName><dynamic>false</dynamic><name>Partition Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Partition</key><value><description>Specifies which Kafka Partition to add the message to. If using a message delimiter, all messages in the same FlowFile will be sent to the same partition. If a partition is specified but is not valid, then all messages within the same FlowFile will use the same partition but it remains undefined which partition is used.</description><displayName>Partition</displayName><dynamic>false</dynamic><name>Partition</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Kafka Key</key><value><description>The Key to use for the Message</description><displayName>Kafka Key</displayName><dynamic>false</dynamic><name>Kafka Key</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Delivery Guarantee</key><value><allowableValues><description>FlowFile will be routed to success after successfully writing the content to a Kafka node, without waiting for a response. This provides the best performance but may result in data loss.</description><displayName>Best Effort</displayName><value>0</value></allowableValues><allowableValues><description>FlowFile will be routed to success if the message is received by a single Kafka node, whether or not it is replicated. This is faster than &lt;Guarantee Replicated Delivery&gt; but can result in data loss if a Kafka node crashes</description><displayName>Guarantee Single Node Delivery</displayName><value>1</value></allowableValues><allowableValues><description>FlowFile will be routed to failure unless the message is replicated to the appropriate number of Kafka Nodes according to the Topic configuration</description><displayName>Guarantee Replicated Delivery</displayName><value>all</value></allowableValues><defaultValue>0</defaultValue><description>Specifies the requirement for guaranteeing that a message is sent to Kafka</description><displayName>Delivery Guarantee</displayName><dynamic>false</dynamic><name>Delivery Guarantee</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Message Delimiter</key><value><description>Specifies the delimiter (interpreted in its UTF-8 byte representation) to use for splitting apart multiple messages within a single FlowFile. If not specified, the entire content of the FlowFile will be used as a single message. If specified, the contents of the FlowFile will be split on this delimiter and each section sent as a separate Kafka message. Note that if messages are delimited and some messages for a given FlowFile are transferred successfully while others are not, the messages will be split into individual FlowFiles, such that those messages that were successfully sent are routed to the 'success' relationship while other messages are sent to the 'failure' relationship.</description><displayName>Message Delimiter</displayName><dynamic>false</dynamic><name>Message Delimiter</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Buffer Size</key><value><defaultValue>5 MB</defaultValue><description>The maximum amount of data to buffer in memory before sending to Kafka</description><displayName>Max Buffer Size</displayName><dynamic>false</dynamic><name>Max Buffer Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Max Record Size</key><value><defaultValue>1 MB</defaultValue><description>The maximum size that any individual record can be.</description><displayName>Max Record Size</displayName><dynamic>false</dynamic><name>Max Record Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Communications Timeout</key><value><defaultValue>30 secs</defaultValue><description>The amount of time to wait for a response from Kafka before determining that there is a communications error</description><displayName>Communications Timeout</displayName><dynamic>false</dynamic><name>Communications Timeout</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Async Batch Size</key><value><defaultValue>200</defaultValue><description>The number of messages to send in one batch. The producer will wait until either this number of messages are ready to send or &quot;Queue Buffering Max Time&quot; is reached. NOTE: This property will be ignored unless the 'Message Delimiter' property is specified.</description><displayName>Batch Size</displayName><dynamic>false</dynamic><name>Async Batch Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Queue Buffering Max Time</key><value><defaultValue>5 secs</defaultValue><description>Maximum time to buffer data before sending to Kafka. For example a setting of 100 ms will try to batch together 100 milliseconds' worth of messages to send at once. This will improve throughput but adds message delivery latency due to the buffering.</description><displayName>Queue Buffering Max Time</displayName><dynamic>false</dynamic><name>Queue Buffering Max Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Compression Codec</key><value><allowableValues><description>Compression will not be used for any topic.</description><displayName>None</displayName><value>none</value></allowableValues><allowableValues><description>Compress messages using GZIP</description><displayName>GZIP</displayName><value>gzip</value></allowableValues><allowableValues><description>Compress messages using Snappy</description><displayName>Snappy</displayName><value>snappy</value></allowableValues><defaultValue>none</defaultValue><description>This parameter allows you to specify the compression codec for all data generated by this producer.</description><displayName>Compression Codec</displayName><dynamic>false</dynamic><name>Compression Codec</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Client Name</key><value><description>Client Name to use when communicating with Kafka</description><displayName>Client Name</displayName><dynamic>false</dynamic><name>Client Name</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>10 sec</penaltyDuration><properties><entry><key>Known Brokers</key><value>sandbox.hortonworks.com:6667</value></entry><entry><key>Topic Name</key><value>critmsgs</value></entry><entry><key>Partition Strategy</key></entry><entry><key>Partition</key></entry><entry><key>Kafka Key</key></entry><entry><key>Delivery Guarantee</key></entry><entry><key>Message Delimiter</key><value>;;</value></entry><entry><key>Max Buffer Size</key></entry><entry><key>Max Record Size</key></entry><entry><key>Communications Timeout</key></entry><entry><key>Async Batch Size</key></entry><entry><key>Queue Buffering Max Time</key><value>1 secs</value></entry><entry><key>Compression Codec</key></entry><entry><key>Client Name</key><value>nifi-applog-processor</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>PutAppLogsToKafka</name><relationships><autoTerminate>true</autoTerminate><description>Any FlowFile that cannot be sent to Kafka will be routed to this Relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Any FlowFile that is successfully sent to Kafka will be routed to this Relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.kafka.PutKafka</type></processors><processors><id>c8c69096-d30a-409d-a9f8-d21ff6c0bb02</id><parentGroupId>754b7b45-9a4c-4a08-bc09-6d7c28965055</parentGroupId><position><x>-486.9551959571231</x><y>520.9753804459021</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Match Requirement</key><value><allowableValues><displayName>content must match exactly</displayName><value>content must match exactly</value></allowableValues><allowableValues><displayName>content must contain match</displayName><value>content must contain match</value></allowableValues><defaultValue>content must match exactly</defaultValue><description>Specifies whether the entire content of the file must match the regular expression exactly, or if any part of the file (up to Content Buffer Size) can contain the regular expression in order to be considered a match</description><displayName>Match Requirement</displayName><dynamic>false</dynamic><name>Match Requirement</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Character Set</key><value><defaultValue>UTF-8</defaultValue><description>The Character Set in which the file is encoded</description><displayName>Character Set</displayName><dynamic>false</dynamic><name>Character Set</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Content Buffer Size</key><value><defaultValue>1 MB</defaultValue><description>Specifies the maximum amount of data to buffer in order to apply the regular expressions. If the size of the FlowFile exceeds this value, any amount of this value will be ignored</description><displayName>Content Buffer Size</displayName><dynamic>false</dynamic><name>Content Buffer Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>ALL</key><value><description></description><displayName>ALL</displayName><dynamic>true</dynamic><name>ALL</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>CRIT</key><value><description></description><displayName>CRIT</displayName><dynamic>true</dynamic><name>CRIT</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>ERROR</key><value><description></description><displayName>ERROR</displayName><dynamic>true</dynamic><name>ERROR</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>10 sec</penaltyDuration><properties><entry><key>Match Requirement</key><value>content must contain match</value></entry><entry><key>Character Set</key></entry><entry><key>Content Buffer Size</key></entry><entry><key>ALL</key><value>[a-zA-Z0-9]</value></entry><entry><key>CRIT</key><value>CRIT</value></entry><entry><key>ERROR</key><value>ERROR</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>RouteOnContent</name><relationships><autoTerminate>false</autoTerminate><description></description><name>ALL</name></relationships><relationships><autoTerminate>false</autoTerminate><description></description><name>CRIT</name></relationships><relationships><autoTerminate>false</autoTerminate><description></description><name>ERROR</name></relationships><relationships><autoTerminate>false</autoTerminate><description>FlowFiles that do not match any of the user-supplied regular expressions will be routed to this relationship</description><name>unmatched</name></relationships><state>STOPPED</state><style/><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.RouteOnContent</type></processors><processors><id>58bf76f0-bb42-4cdc-9b0c-c003e9d23a8e</id><parentGroupId>754b7b45-9a4c-4a08-bc09-6d7c28965055</parentGroupId><position><x>-224.3627117451357</x><y>299.39020378872794</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>ZooKeeper Connection String</key><value><description>The Connection String to use in order to connect to ZooKeeper. This is often a comma-separated list of &lt;host&gt;:&lt;port&gt; combinations. For example, host1:2181,host2:2181,host3:2188</description><displayName>ZooKeeper Connection String</displayName><dynamic>false</dynamic><name>ZooKeeper Connection String</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Topic Name</key><value><description>The Kafka Topic to pull messages from</description><displayName>Topic Name</displayName><dynamic>false</dynamic><name>Topic Name</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Zookeeper Commit Frequency</key><value><defaultValue>60 secs</defaultValue><description>Specifies how often to communicate with ZooKeeper to indicate which messages have been pulled. A longer time period will result in better overall performance but can result in more data duplication if a NiFi node is lost</description><displayName>Zookeeper Commit Frequency</displayName><dynamic>false</dynamic><name>Zookeeper Commit Frequency</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Batch Size</key><value><defaultValue>1</defaultValue><description>Specifies the maximum number of messages to combine into a single FlowFile. These messages will be concatenated together with the &lt;Message Demarcator&gt; string placed between the content of each message. If the messages from Kafka should not be concatenated together, leave this value at 1.</description><displayName>Batch Size</displayName><dynamic>false</dynamic><name>Batch Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Message Demarcator</key><value><defaultValue>\n</defaultValue><description>Specifies the characters to use in order to demarcate multiple messages from Kafka. If the &lt;Batch Size&gt; property is set to 1, this value is ignored. Otherwise, for each two subsequent messages in the batch, this value will be placed in between them.</description><displayName>Message Demarcator</displayName><dynamic>false</dynamic><name>Message Demarcator</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Client Name</key><value><defaultValue>NiFi-58bf76f0-bb42-4cdc-9b0c-c003e9d23a8e</defaultValue><description>Client Name to use when communicating with Kafka</description><displayName>Client Name</displayName><dynamic>false</dynamic><name>Client Name</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Group ID</key><value><defaultValue>58bf76f0-bb42-4cdc-9b0c-c003e9d23a8e</defaultValue><description>A Group ID is used to identify consumers that are within the same consumer group</description><displayName>Group ID</displayName><dynamic>false</dynamic><name>Group ID</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kafka Communications Timeout</key><value><defaultValue>30 secs</defaultValue><description>The amount of time to wait for a response from Kafka before determining that there is a communications error</description><displayName>Kafka Communications Timeout</displayName><dynamic>false</dynamic><name>Kafka Communications Timeout</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>ZooKeeper Communications Timeout</key><value><defaultValue>30 secs</defaultValue><description>The amount of time to wait for a response from ZooKeeper before determining that there is a communications error</description><displayName>ZooKeeper Communications Timeout</displayName><dynamic>false</dynamic><name>ZooKeeper Communications Timeout</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Auto Offset Reset</key><value><allowableValues><displayName>smallest</displayName><value>smallest</value></allowableValues><allowableValues><displayName>largest</displayName><value>largest</value></allowableValues><defaultValue>largest</defaultValue><description>Automatically reset the offset to the smallest or largest offset available on the broker</description><displayName>Auto Offset Reset</displayName><dynamic>false</dynamic><name>Auto Offset Reset</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>10 sec</penaltyDuration><properties><entry><key>ZooKeeper Connection String</key><value>localhost:2181</value></entry><entry><key>Topic Name</key><value>logdemo</value></entry><entry><key>Zookeeper Commit Frequency</key></entry><entry><key>Batch Size</key></entry><entry><key>Message Demarcator</key></entry><entry><key>Client Name</key></entry><entry><key>Group ID</key></entry><entry><key>Kafka Communications Timeout</key></entry><entry><key>ZooKeeper Communications Timeout</key></entry><entry><key>Auto Offset Reset</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>GetAppLogsFromKafka</name><relationships><autoTerminate>false</autoTerminate><description>All FlowFiles that are created are routed to this relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.kafka.GetKafka</type></processors></snippet><timestamp>10/09/2016 01:13:23 UTC</timestamp></template>